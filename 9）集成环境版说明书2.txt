[size=24]DeepFaceLab - нейросеть, меняющая лица в видео.[/size]

[b]Год/Дата Выпуска[/b]: 2018
[b]Версия[/b]: от 04.08.2018
[b]Разработчик[/b]: iperov
[b]Сайт разработчика[/b]: https://github.com/iperov/DeepFaceLab
[b]Разрядность[/b]: 64bit
[b]Язык интерфейса[/b]: Русский/Английский
[b]Таблэтка[/b]: не требуется
[b]Минимальные системные требования[/b]: Windows 7 и выше, GeForce GT730 и выше с [b]2GB видео памяти[/b], 4Gb ОЗУ, Intel Core процессор с поддержкой AVX инструкций
[b]Рекомендуемые системные требования[/b]: Windows 7 и выше, GeForce GTX1060 и выше с [b]6GB видео памяти[/b], 8Gb ОЗУ, Intel Core процессор с поддержкой AVX инструкций
[b]Описание[/b]:
Программа для изменения лиц в видео с помощью нейросети, работающей на графическом ускорителе GeForce.

Это полностью переделенная с нуля оригинальная FaceSwap с фиксами багов и новыми возможностями.

[b]Приступая, поймите:[/b] эта программа не гарантирует идеальной замены лиц во всех случаях! Всё зависит от качества исходных данных, совместимости лиц, источников света, итд итп. Да и сама технология появилась недавно, она далека от идеала, т.к. заменяется только лицо причем без лба и волос. Вы можете потратить кучу времени и сил, а в итоге ничего не получить!

У вас есть невысокий шанс создания успешного фейка с первой попытки.
Только когда вы сделаете много попыток создания фейков с разными лицами, тогда вы поймете все нюансы, чтобы лучше определять, что и как можно фейчить.

Отличия DeepFaceLab:

Внимание: наборы лиц от FaceSwap или FakeApp [b]НЕ подходят[/b]. Нужно извлекать заново, но теперь сделать это проще.

1) полностью переделанная архитектура программы, с которой легче экспериментировать с новыми моделями, если вы шарите в питоне и нейронных сетях
2) отсутствие необходимости любых предустановок, кроме geforce драйверов на видеокарту. Проверено на чистых Windows 7 и 10
3) добавлены новые различные модели
4) добавлена опция отладки для извлечения, тренировки и наложения лиц
5) работает на 2GB видеокартах даже довольно старых GT7xx и выше (извлечение + одна модель), больше видеопамяти - больше моделей доступно.
6) автоматически выбирает лучшую видеокарту. Так можно работать офисно на видеокарте послабже, а обсчёт будет автоматически на лучшей.
7) для извлечения лиц автоматически используются все подходящие видеокарты. Для тренировки моделей есть мульти-gpu режим, но только если в системе будут обнаружены идентичные видеокарты.
8) добавлен новый детектор лиц называемый MTCNN. В отличие от DLIBCNN он выдает меньше дрожания в извлеченных лицах, но выделяет также и ложные лица, которые можно быстро удалить утилитой сортировки. Также MTCNN быстрее и запускается 1 процесс на каждые 2Гб видеопамяти каждой доступной видеокарты.
9) добавлен режим ручного выделения лиц, там где детектор ничего не нашел
10) есть режим полностью ручного выделения лиц - нужно только для dst набора лиц, т.к. пропущенные src лица погоды не сделают
11) более не нужно предварительно обрабатывать dst видео, вырезая только те куски, где присутствует нужное лицо - теперь заменяются только те лица, которые реально тренировались в сети.
12) добавлена сортировка извлеченных лиц для быстрого удаления ненужных
13) есть возможность вырезать нужный кусок целевого видео
13) сборка финального видео использует звук из оригинального

пример фейка, тренированного на ноутбуке с 2GB gtx850m за сутки:  https://www.youtube.com/watch?v=bprVuRxBA34

[spoiler="Инструкция по работе с программой"]

И так приступим.

Почему нет графического интерфейса? Опций в программе не слишком много, чтобы делать графический интерфейс. К тому же оно будет создавать третье окно при тренировке, что уже слишком много.

В начале я хотел сделать bat запускалки на русском языке, но пусть они будут на английском языке, т.к. информация в программе всё равно на английском.

Определим термин dst,src.
src - это лицо, которым мы будем заменять
dst - это лицо, которое будет заменяться

! Данная инструкция [b]протестирована[/b] на [/b]чистых Windows[/b] 7 и 10 !

[b]Обновите[/b] драйвера на вашу GeForce видеокарту.

[b]Далее[/b] по порядку:

DeepFaceLab\[b]workspace[/b] - наша [b]рабочая[/b] папка для хранения модели целиком (видео, фото, файлы самой программы).

[b]1) clear workspace.bat[/b] - [b]очистит[/b] или создаст все папки внутри папки workspace

Кладёте в папку [b]workspace[/b] ваше видео [b]data_src.xxx[/b] формата максимум [b]1080р[/b] - это видео [b]откуда брать лицо[/b]. Тестовое видео уже содержится в папке workspace.
Кладёте в папку [b]workspace[/b] ваше видео [b]data_dst.xxx[/b] формата максимум [b]1080р[/b] - это видео [b]где заменить лицо[/b]. Тестовое видео уже содержится в папке workspace.

где [b]xxx[/b] - любое расширение видео, например mkv, mp4, avi

[b]2) extract PNG from video data_src ... .bat[/b] - конвертирует видео [b]откуда брать лицо[/b] в набор PNG в [b]workspace\data_src[/b]

Здесь мы собираем кадры из которых будем извлекать src лица. Чем их больше тем лучше.
Есть на выбор 1,5, 10, или полные FPS.
Какой выбрать? Зависит от того, сколько времени нужное лицо содержится в видео.
Если это 3х часовая речь, то 1-5 FPS.
до 1.5ч - 10 FPS.
до 10 минут - полные FPS.

[b]3.1) cut video data_dst (edit me).bat[/b] - опционально.

Обрезает видео [b]где заменить лицо[/b], на время которое вы укажите [b]отредактировав файл[/b] блокнотом внутри этого файла .bat

пример: 00:05:00 00:00:55.20 вырежет 55.20 (сотых) секунд, начиная с 5-й минуты, остальное отбросит.

Тестовое видео, которое уже лежит в папке, обрезать не нужно.

[b]3.2) extract PNG from video data_dst.bat[/b] - конвертирует видео [b]где заменить лицо[/b] в набор PNG в [b]workspace\data_dst[/b]

Здесь извлечение только с ПОЛНЫМ FPS, потому что каждый кадр должен быть обработан.

[b]4) data_src extract faces ... .bat[/b] - производит выборку [b]конечного набора лиц[/b] из PNG в папку [b]workspace\data_dst\aligned[/b]

[b]Опциии[/b]:

[b]DLIB, MT детекторы.[/b]
Для src [b]оптимально[/b] MT детектор.
DLIB - медленнее, лица получаются с некоторым дрожанием, но производит меньше ложных лиц.
MT - быстрее, меньше дрожания лиц, но производит больше ложных лиц.

[b]GPU[/b]
Здесь либо [b]ALL[/b] (все), либо [b]Best[/b] (лучший).
Если у вас только 1 GPU, то нет разницы, что выбирать.
Если вы офисно работаете на слабом GPU, а имеется мощный, то выбираете [b]Best[/b].
Для максимальной скорости на мульти-GPU выбираете [b]ALL[/b], но тогда офисная работа на основном GPU может подтормаживать.

[b]отладка[/b]
Записывает в workspace\data_src\aligned_debug каждый кадр с выделенными лицами и лицевыми точками, тем самым можно смотреть работу детекторов.

[b]4.1) data_src check result.bat[/b] - просмотр результатов выборки лиц с помощью портативной программы FSViewer.

Здесь ваша цель убрать ненужные лица.
Сначала пролистываете скролом и убираете те ненужные лица, которые идут подряд группами.
Если нужное лицо перемешано с другими, то запускаете сортировки следующих пунктах.
Сортировку по резкости в любом случае делаете, потому что мутные лица нужно удалять.

[b]4.2.1) data_src sort by blur.bat[/b]

Сортировка по резкости. Запускаете и ждете сортировки. Затем смотрите результаты. Самые мутные лица будут в конце. Просто удаляете все файлы начиная с середины списка и до конца.

[b]4.2.2) data_src sort by similar histogram.bat[/b]

После этой сортировки лица будут сгруппированы по содержанию, так что отсеять ненужные лица теперь намного проще.
Проходите скроллом и удаляете ненужные лица группами.

[b]4.2.3) data_src sort by similar histogram and blur.bat[/b]
Опциональный пункт. Сортирует по схожему контенту + по резкости, т.е. в конце каждых групп схожих изображений будут размытые изображения.

[b]4.2.4) data_src sort by dissimlar histogram.bat[/b]

Эта сортировка оставляет ближе к концу списка те изображения, у которых больше всего похожих.
Обычно это лица в анфас, которых больше всего, потому что актёр чаще смотрит прямо на камеру либо куда-то в одном направлении в интервью.
Часть с конца списка можете удалить по усмотрению.
Также этой сортировкой можно идеально прореживать набор лиц. К примеру у вас получилось 5000, но для работы нейронной сети оптимально 1500, то выбираете первые 1500 лиц после этой сортировки, а остальное удаляете.

[b]4.2.5) data_src sort by face yaw.bat[/b]

Опциональный пункт. Сортирует лица так, чтобы вначале списка лицо смотрело налево, а к концу списка - направо.
По сути просто приводит набор лиц в конечный надлежащий для человека вид (для программы нет разницы), который можно сохранить в отдельной папке для будущего использования.

[b]Итог по извлечению лиц src.[/b]

Ваша цель собрать как минимум 1000 лиц разного угла поворота.
Мутные лица надо удалять.
Лица закрывающиеся чем-то (рукой, волосами, итд) - также нужно удалять.
Много близких лиц в анфас - удалять.
Сокращаете набор лиц до количества 1000-1500 только после сортировки [b]по непохожей хистограмме[/b].
Вы можете собрать несколько разных конечных наборов лиц одного актёра и затем использовать их в зависимости от условий лица dst, помещая их в папку [b]data_src\aligned[/b]
Как показала практика, лучше не смешивать лица с разным освещением и тенями на лице.

[b]5) data_dst extract faces ... .bat[/b]
То же, что и п.4, с некоторыми отличиями.
Здесь мы извлекаем лицо, которое будет заменяться.

Детектор DLIB или MT ?
В большинстве случаев - MT.
Если лицо не определилось в каком-то кадре, то для этого есть опция [b]+исправить[/b] - позволяет вручную указать лица на кадрах, где вообще не определилось никаких лиц.
Подвох с MT+исправить в том, что на кадре могут определиться левые лица кроме главного, поэтому программа не предложит указать лица на этом кадре. В таком случае можете проверять с отладкой какие лица обнаружились вообще.
Можете использовать DLIB+исправить, он почти не генерирует ложных лиц.
В совсем крайнем случае или для экспериментов есть полностью [b]РУЧНАЯ[/b] выборка, т.е. по каждому исходному кадру dst вы вручную проходите и указываете лица.

[b]Окно ручного исправления лиц.[/b] (см скриншоты)

здесь вам нужно совместить зеленые точки с лицом.

[b]Управление:[/b]

Enter - подтвердить лицо и следующий кадр.
Пробел - пропустить кадр.
Колесо мыши - изменять прямоугольник.

[b]5.1) data_dst check results.bat[/b]

Аналогично смотрим результаты выборки лица dst, и удаляем [b]другие не целевые[/b] лица. А [b]целевое[/b] лицо, даже мутные - оставляем.

[b]5.2) data_dst sort by similar histogram.bat[/b]

Если в целевом видео содержатся много других лиц, можете произвести эту сортировку, и затем удалить эти лица будет проще.

[b]Итог по извлечению лиц dst.[/b]

Ваша цель извлечь ТОЛЬКО целевое лицо (даже мутное) из каждого кадра, удалив все другие лица.

[b]6) train ... Тренировка.[/b]

[b]Отключаем[/b] любые программы, которые могут использовать [b]видео память[/b].

Касательно GPU опций:
[b]Best GPU[/b] - аналогично описанному ранее, используется лучший GPU если их несколько в системе.
а вот [b]Multi GPU[/b] - активирует режим мульти-GPU, только если в системе обнаружены идентичные модели GPU, например ДВЕ одинаковые GTX1060 6GB. Тогда тренировка размазывается по ним.

Опция [b]debug[/b] - позволяет посмотреть какие сэмплы генерируются на вход в нейронную сеть.

[b]Виды моделей:[/b]

Также указано минимальные требования к памяти GPU.

H64 (2GB+) - половина лица с разрешением 64 - это как оригинальная FakeApp или FaceSwap, только лучше за счёт тренировки маски нейросетью + исключающей фон вокруг лица + исправленного конвертора. Для видеокарт с видеопамятью 2 и 3Гб данная модель работает в сокращенном режиме, т.е. качество будет хуже чем с 4гБ.
H128 (3GB+)- как H64 только с разрешением 128 - максимальные детали лиц можно достигнуть только этой моделью, за счёт половины лица. Однако половина лица может плохо обучится на некоторых условиях света и поворота головы итд. Для видеокарт с видеопамятью 3 и 4Гб данная модель работает в сокращенном режиме, т.е. качество будет хуже чем с 5гБ.
DF (5GB+) - модель от dfaker. Полнолицевая модель с разрешением 128, умная функция тренировки лиц, исключающая фон вокруг лица.
LIAEF128 (5GB+) - новая модель, как DF, только пытается морфировать исходное лицо в целевое лицо, сохраняя черты исходного лица. Морфирование не всегда хорошо, и может сделать вообще не узнаваемое лицо, в таком случае выбирайте DF.
LIAEF128YAW (5GB+) - тестовая модель, как LIAEF128, только на вход в нейронку поступают src лица со схожим направлением как и dst.
MIAEF128 (5GB+) - так же как LIAEF128, плюс тренирует сходство по яркости/цвету, может генерировать жуткие лица. Хорошо показала себя в тёмных фильмовых сценах.
AVATAR (4GB+) - модель для управления лицом. Результат не выдающийся. См как с ней работать ниже.

Вы можете тренировать все модели поочередно, не волнуясь о потери данных, потому что каждая модель записывается в свои файлы в папке [b]Workspace\Model\[/b]

В процессе тренировки можно выходить через [b]Enter[/b], нажав его в [b]окне Training preview[/b], и запускать в любое время, модель будет продолжать обсчитываться с той же точки.
Тренируем от 24 часов и больше. Когда результат удовлетворяет - выходим также через [b]Enter[/b], нажав его в [b]окне Training preview[/b].

Кнопка 'p'(на англ раскладке) в [b]окне Training preview[/b] обновляет предпросмотр.

В [b]окне Training preview[/b] также мы видим [b]кривую ошибки[/b]. Четкость результата может увеличиваться в процессе тренировки и без понижения кривой ошибки.

[b]7) convert ... Наложение лиц.[/b]

Выбираете ту модель, с которой тренировали.

Опция [b]debug[/b] позволяет посмотреть процесс наложения лиц и некоторую техническую информацию по каждому кадру в консоли, нажимаете пробел в окне просмотра.

Далее при запуске программа спросит об опциях:

[i]Choose mode: (1) hist match, (2) hist match bw, (3) seamless (default), (4) seamless hist match : [/i]

Выбор режима наложения лиц.
По-умолчанию, если нажать ентер - выберет seamless.
Какую выбрать? Зависит от случая. Пробуете все и смотрите результат.

[i]Masked hist match? [0..1] (default - model choice) :[/i]

Для режимов (1) hist match, (2) hist match bw указывает, уравнивать ли гистограмму по маске лица. По-умолчанию нажав ентер - отдаёт решение конкретной модели.

[i]Choose erode mask modifier [-100..100] (default 0) :[/i]

Указываете насколько сжать лицевую маску. Значение < 0 - расширить маску.
В отличие от FaceSwap этот параметр модифицирует адаптивное значепние, а не абсолютное.

[i]Choose blur mask modifier [-100..200] (default 0) : [/i]

Указываете насколько сгладить лицевую маску. Значение < 0 - уменьшает сглаживание по-умолчанию моделями H64 и H128.
В отличие от FaceSwap этот параметр модифицирует адаптивное значепние, а не абсолютное.

[b]Итог по наложению лиц.[/b]

В начале запускаете с отладкой, пробуя различные параметры и смотрите результат.
Если значения erode и blur по-умолчанию не устраивают в результате, то отталкиваетесь от значений 50 и 70 соответственно.
Запомнив подходящие значения, запускаете наложение без отладки.

Результат картинок в [b]workspace\data_dst\merged[/b] - можно использовать самому в [b]видеоредакторе[/b], либо [b]склеить[/b] в видео в п.8

[b]8) converted to avi.bat[/b]
[b]8) converted to mp4.bat[/b]

Склеивает картинки в видео в [b]workspace\result.avi[/b] с тем же FPS и звуком, что и [b]data_dst.mp4[/b] - поэтому не удаляйте [b]data_dst.mp4[/b] из workspace папки.

[b]Всё[/b]. Результат в [b]workspace\result.avi[/b].

Если результат [b]не удовлетворил[/b], можно пробовать разные опции наложения, либо редактировать опции наложения командной строки(см. ниже), либо продолжать тренировать для повышения четкости, либо пробовать другую модель, либо пробовать другое исходное лицо.

[b]Дополнительная[/b] информация:

Раньше были [b]workspace backup.bat[/b], для бэкапа, но я их убрал, потому что можно и НУЖНО вручную скопировать и переименовать workspace например в workspace_собчак, тем самым сохранив резервную копию.
[/spoiler]

[spoiler="Как работать с AVATAR моделью"]
[url=https://coub.com/view/1954x3]Пример AVATAR модели[/url]
[url=https://www.youtube.com/watch?v=3M0E4QnWMqA]Еще пример AVATAR модели[/url]

Эта инструкция требует некоторых ручных действий с файлами.

В src должно быть то лицо, которым управляем. Требования к нему: должно быть из одного интервью, фон не должен сильно меняться.
Подготовка src аналогична обычным моделям.

В dst лицо - которое управляет.
В начале подготавливаете dst лица как для обычной модели от 500 штук.
Эту aligned папку в data_dst переименовываете во временную aligned_tmp
Обрезаете data_dst.mp4 на тот кусок, который будет непрывно управлять лицом, например первые 15 секунд.
Извлекаете лица как обычно через MT.
Через сортировку по гистограмме нужно убрать ложные лица. Основное лицо даже мутное оставляем.
Запустить [b]5.3) data_dst sort by original filename.bat[/b] , это восстановит оригинальный порядок файлов, потому что сортировка по гистограмме переименовывает их в другой порядок.
Из data_dst\aligned скопировать всё в data_dst\ , т.е. этот кусок из видео мы превратили в набор извлеченного лица, этот набор будет использоваться для конвертации, так же как в обычных моделях используются первоначальные кадры.
Папку data_dst\aligned удалить.
Папку data_dst\aligned_tmp переименовать назад в data_dst\aligned
В итоге, что мы имеем: data_dst\aligned может содержать тысячу лиц, которые нужны для правильного анализа лица.
А в data_dst\ мы имеем непрерывный набор извлеченного 256х256 лица, который будет использоваться при конвертации.
Для тренировки использоваться соответствующий 6) train AVATAR
Для конвертации 7) convert AVATAR
Соответственно при сборке mp4 , в workspace должен храниться обрезанный data_dst.mp4, чтобы звук корректно наложился.
[/spoiler]

[spoiler="Нехватка памяти на Windows 10"]
Известны случаи, когда Windows 10 резервирует % видеопамяти, даже если видеокарта не используется для вывода картинки. В таком случае есть шанс, что вы не сможете использовать некоторые модели.
[/spoiler]

[spoiler="Опции командной строки"]
Дополнительные опции тренировки. Редактировать соответствующий .bat файл.

--write-preview-history - записывает в [b]Workspace\Model\Model_##_history\[/b] набор картинок отображающий ход тренировки.

--target-epoch N - тренировка остановится по достижению N эпохи

--force-best-gpu-idx N - принудительная установка номера GPU как лучшего
либо
--force-gpu-idxs 0,1 - принудительный выбор 0,1 GPU для использования
[/spoiler]

[spoiler="Полезные ссылки"]
[url=https://mega.nz/#F!y1ERHDaL!PPwg01PQZk0FhWLVo5_MaQ]Готовые src наборы лиц для DeepFaceLab[/url]
[url=http://www.pictriev.com/]поиск подходящей знаменитости по загруженному лицу[/url]
[url=https://findface.sex/ru/#]поиск подходящей порнозвезды по загруженному лицу[/url]

[url=https://www.youtube.com/channel/UCEtoVzBLuE-ni-54h7kYvsg]Мой канал фейков[/url]
[url=https://coub.com/view/1954x3]Пример AVATAR модели[/url]
[url=https://www.youtube.com/watch?v=3M0E4QnWMqA]Еще пример AVATAR модели[/url]
[/spoiler]

[spoiler="Скриншоты"]
Ручное извлечение:
[img]http://i104.fastpic.ru/big/2018/0418/0f/f510f562f872a895b6119875f9d30f0f.png[/img]

Тренировка модели:
[img]http://i104.fastpic.ru/big/2018/0418/1e/bb8f3e70b350dbe73d902dd344be5e1e.png[/img]
[/spoiler]

[spoiler="Скриншот папки DeepFaceLab"]
[img]http://i105.fastpic.ru/big/2018/0507/57/d8de438a901a58493135ba1d4217fa57.jpg[/img]
[/spoiler]

[color=red]раздача обновлена[/color]

конвертор теперь работает в параллеле, что увеличило скорость конвертации в 2 раза

[color=red]раздача обновлена[/color]

пофиксил склейку в mp4 - теперь видео корректно грузится в Sony Vegas

[color=red]раздача обновлена[/color]

фикс ошибок на некоторых сэмплах

введена тестовая модель LIAEF128YAW

[color=red]раздача обновлена[/color]

фикс сортировки по хистограммам
добавлены сортировка по яркости, цвету, хистограммо-размытости

[color=red]раздача обновлена[/color]

Нужно перезапустить тренировку всех моделей (удалить папку model из workspace)
Апгрейд движка на TensorFlow 1.8.0, CUDA 9.0, CuDNN 7.0
Улучшено качество всех моделей.
До/после LIAEF128 https://www.youtube.com/watch?v=_52EaJi1USI
H128 Кейдж https://github.com/iperov/DeepFaceLab/raw/master/doc/H128_Cage_0.jpg

[color=red]раздача обновлена[/color]

проект переименован в DeepFaceLab
апгрейд движка на Python 3.6.5.
улучшено качество тренировки моделей
улучшено качество конвертора
рекомендуется (но не обязательно) перезапустить тренировки

[color=red]раздача обновлена[/color]

фикс зависающей выборки лиц

[color=red]раздача обновлена[/color]

фиксы
улучшено качество извлечения лиц
изменены минимальные требования видеопамяти для моделей
H128 для 4Гб запускается урезанной версией как и для 3Гб.

[color=red]раздача обновлена[/color]

фикс серьезного бага с которым модель не учила половину лиц

[color=red]раздача обновлена[/color]

фиксы
Ускорена тренировка моделей H64 и H128 от 7 до 15%.
Добавлена AVATAR модель. Пример https://coub.com/view/1954x3
фикс бага финальной сборки mp4, когда изначальное видео имело нестандартный кодек, например снятое из смартфона