[size=24]DeepFaceLab - нейросеть, меняющая лица в видео.[/size]

[b]Год/Дата Выпуска[/b]: 2019
[b]Версия[/b]: от 26.01.2019
[b]Разработчик[/b]: iperov
[b]Сайт разработчика[/b]: https://github.com/iperov/DeepFaceLab
[b]Разрядность[/b]: 64bit
[b]Язык интерфейса[/b]: Русский/Английский
[b]Таблэтка[/b]: не требуется, способы поддержки автора есть на github странице.
[b]Минимальные системные требования[/b]: Windows 7 и выше, Intel Core процессор с поддержкой AVX инструкций или GTX8xx, 9xx и выше.
[b]Рекомендуемые системные требования[/b]: Windows 7 и выше, GeForce GTX1060 и выше с [b]6GB видео памяти[/b], 8Gb ОЗУ, Intel Core процессор с поддержкой AVX инструкций
[b]Описание[/b]:
Программа для изменения лиц в видео с помощью нейросети, работающей на графическом ускорителе GeForce.

Это полностью переделенная с нуля оригинальная FaceSwap с фиксами багов и новыми возможностями.

[b]Приступая, поймите:[/b] эта программа не гарантирует идеальной замены лиц во всех случаях! Всё зависит от качества исходных данных, совместимости лиц, источников света, итд итп. Да и сама технология появилась недавно, она далека от идеала, т.к. заменяется только лицо причем без лба и волос. Вы можете потратить кучу времени и сил, а в итоге ничего не получить!

У вас есть невысокий шанс создания успешного фейка с первой попытки.
Только когда вы сделаете много попыток создания фейков с разными лицами, тогда вы поймете все нюансы, чтобы лучше определять, что и как можно фейчить.

Отличия DeepFaceLab:

Внимание: наборы лиц от FaceSwap или FakeApp [b]НЕ подходят[/b]. Нужно извлекать заново, но теперь сделать это проще.

- полностью переделанная архитектура программы, с которой легче экспериментировать с новыми моделями, если вы шарите в питоне и нейронных сетях
- отсутствие необходимости любых предустановок, кроме geforce драйверов на видеокарту. Проверено на чистых Windows 7 и 10
- добавлены новые различные модели
- добавлена опция отладки для извлечения, тренировки и наложения лиц
- работает на 2GB видеокартах даже довольно старых некоторых GT7xx и выше (извлечение + одна модель), больше видеопамяти - больше моделей доступно.
- работает полностью на CPU, см CPU версию.
- автоматически выбирает лучшую видеокарту. Так можно работать офисно на видеокарте послабже, а обсчёт будет автоматически на лучшей.
- для извлечения лиц автоматически используются все подходящие видеокарты. Для тренировки моделей есть мульти-gpu режим, но только если в системе будут обнаружены идентичные видеокарты.
- добавлен новый детектор лиц называемый MTCNN. В отличие от DLIBCNN он выдает меньше дрожания в извлеченных лицах, но выделяет также и ложные лица, которые можно быстро удалить утилитой сортировки. Также MTCNN быстрее и запускается 1 процесс на каждые 2Гб видеопамяти каждой доступной видеокарты.
- добавлен режим ручного выделения лиц, там где детектор ничего не нашел
- есть режим полностью ручного выделения лиц - нужно только для dst набора лиц, т.к. пропущенные src лица погоды не сделают
- более не нужно предварительно обрабатывать dst видео, вырезая только те куски, где присутствует нужное лицо - теперь заменяются только те лица, которые реально тренировались в сети.
- добавлена сортировка извлеченных лиц для быстрого удаления ненужных
- есть возможность вырезать нужный кусок целевого видео
- сборка финального видео использует звук из оригинального

пример фейка, тренированного на ноутбуке с 2GB gtx850m за сутки:  https://www.youtube.com/watch?v=bprVuRxBA34

[spoiler="Вводная видео инструкция по работе с программой"]https://www.youtube.com/watch?v=K98nTNjXkq8[/spoiler]
[spoiler="Подробная инструкция по работе с программой"]

И так приступим.

Почему нет графического интерфейса? Опций в программе не слишком много, чтобы делать графический интерфейс. К тому же оно будет создавать третье окно при тренировке, что уже слишком много.

В начале я хотел сделать bat запускалки на русском языке, но пусть они будут на английском языке, т.к. информация в программе всё равно на английском.

Определим термин dst,src.
src - это лицо, которым мы будем заменять
dst - это лицо, которое будет заменяться

! Данная инструкция [b]протестирована[/b] на [/b]чистых Windows[/b] 7 и 10 !

[b]Обновите[/b] драйвера на вашу GeForce видеокарту.

[b]Далее[/b] по порядку:

DeepFaceLab\[b]workspace[/b] - наша [b]рабочая[/b] папка для хранения модели целиком (видео, фото, файлы самой программы).

[b]1) clear workspace.bat[/b] - [b]очистит[/b] или создаст все папки внутри папки workspace. ОСТОРОЖНО, случайное нажатие на этот пункт уже после тренировок, удалит всё из текущего workspace.

Кладёте в папку [b]workspace[/b] ваше видео [b]data_src.xxx[/b] формата максимум [b]1080р[/b] - это видео [b]откуда брать лицо[/b]. Тестовое видео уже содержится в папке workspace.
Кладёте в папку [b]workspace[/b] ваше видео [b]data_dst.xxx[/b] формата максимум [b]1080р[/b] - это видео [b]где заменить лицо[/b]. Тестовое видео уже содержится в папке workspace.

где [b]xxx[/b] - любое расширение видео, например mkv, mp4, avi

[b]2) extract PNG from video data_src ... .bat[/b] - конвертирует видео [b]откуда брать лицо[/b] в набор PNG в [b]workspace\data_src[/b]

Здесь мы собираем кадры из которых будем извлекать src лица. Чем их больше тем лучше.
Есть на выбор 1,5, 10, или полные FPS.
Какой выбрать? Зависит от того, сколько времени нужное лицо содержится в видео.
Если это 3х часовая речь, то 1-5 FPS.
до 1.5ч - 10 FPS.
до 10 минут - полные FPS.

[b]3.1) cut video data_dst (edit me).bat[/b] - опционально.

Обрезает видео [b]где заменить лицо[/b], на время которое вы укажите [b]отредактировав файл[/b] блокнотом внутри этого файла .bat

пример: 00:05:00 00:00:55.20 вырежет 55.20 (сотых) секунд, начиная с 5-й минуты, остальное отбросит.

Тестовое видео, которое уже лежит в папке, обрезать не нужно.

[b]3.2) extract PNG from video data_dst.bat[/b] - конвертирует видео [b]где заменить лицо[/b] в набор PNG в [b]workspace\data_dst[/b]

Здесь извлечение только с ПОЛНЫМ FPS, потому что каждый кадр должен быть обработан.

[b]3.other) denoise extracted data_dst.bat[/b]

делается перед извлечением dst лиц! делает проход по извлеченным видео кадрам убирая шум, сохраняя четкими грани.
Позволяет тем самым сделать финальный фейк более правдоподобным, т.к. нейронная сеть не способна сделать детальную текстуру кожи, но грани делает вполне четкими.
Поэтому, если весь кадр будет более "замылен", то и фейк будет казаться более правдоподобным. Особенно актуально для фильмовых сцен, которые обычно очень четкие.

[b]4) data_src extract faces ... .bat[/b] - производит выборку [b]конечного набора лиц[/b] из PNG в папку [b]workspace\data_dst\aligned[/b]

[b]Опциии[/b]:

[b]DLIB, MT детекторы.[/b]
Для src [b]оптимально[/b] MT детектор.
DLIB - медленнее, лица получаются с некоторым дрожанием, но производит меньше ложных лиц.
MT - быстрее, меньше дрожания лиц, но производит больше ложных лиц.

[b]GPU[/b]
Здесь либо [b]ALL[/b] (все), либо [b]Best[/b] (лучший).
Если у вас только 1 GPU, то нет разницы, что выбирать.
Если вы офисно работаете на слабом GPU, а имеется мощный, то выбираете [b]Best[/b].
Для максимальной скорости на мульти-GPU выбираете [b]ALL[/b], но тогда офисная работа на основном GPU может подтормаживать.

[b]отладка[/b]
Записывает в workspace\data_src\aligned_debug каждый кадр с выделенными лицами и лицевыми точками, тем самым можно смотреть работу детекторов.

[b]4.1) data_src check result.bat[/b] - просмотр результатов выборки лиц с помощью портативной программы FSViewer.

Здесь ваша цель убрать ненужные лица.
Сначала пролистываете скролом и убираете те ненужные лица, которые идут подряд группами.
Если нужное лицо перемешано с другими, то запускаете сортировки следующих пунктах.
Сортировку по резкости в любом случае делаете, потому что мутные лица нужно удалять.

[b]4.2.1) data_src sort by blur.bat[/b]

Сортировка по резкости. Запускаете и ждете сортировки. Затем смотрите результаты. Самые мутные лица будут в конце. Просто удаляете все файлы начиная с середины списка и до конца.

[b]4.2.2) data_src sort by similar histogram.bat[/b]

После этой сортировки лица будут сгруппированы по содержанию, так что отсеять ненужные лица теперь намного проще.
Проходите скроллом и удаляете ненужные лица группами.

[b]4.2.4) data_src sort by dissimlar histogram.bat[/b]

Эта сортировка оставляет ближе к концу списка те изображения, у которых больше всего похожих.
Обычно это лица в анфас, которых больше всего, потому что актёр чаще смотрит прямо на камеру либо куда-то в одном направлении в интервью.
Часть с конца списка можете удалить по усмотрению.
Также этой сортировкой можно идеально прореживать набор лиц. К примеру у вас получилось 5000, но для работы нейронной сети оптимально 1500, то выбираете первые 1500 лиц после этой сортировки, а остальное удаляете.

[b]4.2.other) data_src sort by black.bat[/b]

Сортирует по количеству черных пикселей в конец списка. Позволяет отсеить лица вырезанные экраном.

[b]4.2.5) data_src sort by face yaw.bat[/b]

Опциональный пункт. Сортирует лица так, чтобы вначале списка лицо смотрело налево, а к концу списка - направо.
По сути просто приводит набор лиц в конечный надлежащий для человека вид (для программы нет разницы), который можно сохранить в отдельной папке для будущего использования.

[b]Итог по извлечению лиц src.[/b]

Ваша цель собрать как минимум 1000 лиц разного угла поворота.
Мутные лица надо удалять.
Лица закрывающиеся чем-то (рукой, волосами, итд) - также нужно удалять.
Много близких лиц в анфас - удалять.
Сокращаете набор лиц до количества 1000-1500 только после сортировки [b]по непохожей хистограмме[/b].
Вы можете собрать несколько разных конечных наборов лиц одного актёра и затем использовать их в зависимости от условий лица dst, помещая их в папку [b]data_src\aligned[/b]
Как показала практика, лучше не смешивать лица с разным освещением и тенями на лице.

[b]5) data_dst extract faces ... .bat[/b]
То же, что и п.4, с некоторыми отличиями.
Здесь мы извлекаем лицо, которое будет заменяться.

[b]5.1) data_dst check results debug.bat[/b]
просмотреть все dst кадры с наложенными поверх них предсказанными контурами лица

[b]5) data_dst extract faces MANUAL FIX DELETED ALIGNED DEBUG[/b]
позволяет переизвлечь те кадры из DST, чьи results debug были удалены.
Для чего это нужно? Чтобы сделать фейк качественнее, нужно проверять DST кадры в папке aligned_debug, просмотреть их можно через 5.1) data_dst check results debug.bat
Если где-то увидите, что контур лица сильно отличается от реального, например съехало на фон, то удаляете этот кадр в aligned_debug, и запускаете 5) data_dst extract faces MANUAL FIX DELETED ALIGNED DEBUG
Произойдет ручное переизвлечение удалённых кадров. Видео поясняющее этот процесс: https://www.youtube.com/watch?v=7z1ykVVCHhM

Детектор DLIB или MT ?
В большинстве случаев - MT.
Если лицо не определилось в каком-то кадре, то для этого есть опция [b]+исправить[/b] - позволяет вручную указать лица на кадрах, где вообще не определилось никаких лиц.
Подвох с MT+исправить в том, что на кадре могут определиться левые лица кроме главного, поэтому программа не предложит указать лица на этом кадре. В таком случае можете проверить в папке data_dst\aligned_debug какие лица обнаружились вообще.
Можете использовать DLIB+исправить, он почти не генерирует ложных лиц.
В совсем крайнем случае или для экспериментов есть полностью [b]РУЧНАЯ[/b] выборка, т.е. по каждому исходному кадру dst вы вручную проходите и указываете лица.

[b]Окно ручного исправления лиц.[/b] (см скриншоты)

здесь вам нужно совместить зеленые точки с лицом.

[b]Управление:[/b]

Enter - подтвердить лицо и следующий кадр.
Пробел - пропустить кадр.
Колесо мыши - изменять прямоугольник.

[b]5.1) data_dst check results.bat[/b]

Аналогично смотрим результаты выборки лица dst, и удаляем [b]другие не целевые[/b] лица. А [b]целевое[/b] лицо, даже мутные - оставляем.

[b]5.2) data_dst sort by similar histogram.bat[/b]

Если в целевом видео содержатся много других лиц, можете произвести эту сортировку, и затем удалить эти лица будет проще.

[b]Итог по извлечению лиц dst.[/b]

Ваша цель извлечь ТОЛЬКО целевое лицо (даже мутное) из каждого кадра, удалив все другие лица.

[b]6) train ... Тренировка.[/b]

[b]Отключаем[/b] любые программы, которые могут использовать [b]видео память[/b].

Касательно опций в имени .bat файла тренировки:
[b]без опций[/b] - аналогично описанному ранее, используется лучший GPU если их несколько в системе.
[b]debug[/b] - позволяет посмотреть какие сэмплы генерируются на вход в нейронную сеть.

При первом запуске модели, программа спросит о различных опциях, которые сохранятся и будут использоваться при последующих запусках.

Просто нажимая ентер - будут использоваться значения по-умолчанию.

[i]Which GPU idx to choose? ( skip: system choice ) : [/i] Имея мульти-GPU можно тренировать одну сцену на разных моделях или опциях одной модели без клонирования папок. Просто выбираете индекс GPU на старте тренировки/конвертации и файлы модели будут содержать префикс этой GPU в имени.
Если оставить выбор GPU по-умолчанию, то выберется лучшая GPU и файлы модели НЕ будут содержать префикс.

[i]Write preview history? (y/n skip:n) : [/i] - писать ли историю превью на диск
[i]Target epoch (skip:unlimited) : [/i] - целевая эпоха, по достижению которой тренировка остановится.
[i]Batch_size (skip:model choice) : [/i] - выбор размера батча модели, это то сколько картинок за раз кормится нейронной сети для обучения. По-умолчанию выбирает модель, но вы можете подобрать это значение самому под свою видеокарту. Чем больше - тем лучше.
[i]Feed faces to network sorted by yaw? (y/n skip:n) : [/i] - кормит модели src лица отсортированные по такому же направлению как и dst. Смысл в том чтобы не кормить не нужные лица. Однако пока до конца не протестировано хорошо это или плохо.
[i]Flip faces randomly? (y/n ?:help skip:y) : [/i] - кормит модели все лица случайно перевернутые по горизонтали. При выключенной опции финальное лицо будет более естественным, но тогда src сборка лиц должна покрывать все углы поворота.
[i]Src face scale modifier % ( -30...30, ?:help skip:0) : [/i] - модификатор масштабирования для src лиц. Если src лицо более широкое чем dst и фейк получился плохим, то имеет смысл немного убавить это значение, особенно актуально для SAE.

При НЕ первом запуске модели, спросит:
[i]Press enter in 2 seconds to override some model settings.[/i]
если вы нажмете ентер втечение 2х секунд, то появится возможность заменить некоторые опции модели.

[b]Виды моделей:[/b]

Также указано минимальные требования к памяти GPU.

H64 (2GB+) - половина лица с разрешением 64 - это как оригинальная FakeApp или FaceSwap, только лучше за счёт тренировки маски нейросетью + исключающей фон вокруг лица + исправленного конвертора. Для видеокарт с видеопамятью 2 и 3Гб данная модель работает в сокращенном режиме, т.е. качество будет хуже чем с 4гБ.

H128 (3GB+)- как H64 только с разрешением 128 - максимальные детали лиц можно достигнуть только этой моделью, за счёт половины лица. Однако половина лица может плохо обучится на некоторых условиях света и поворота головы итд. Для видеокарт с видеопамятью 3 и 4Гб данная модель работает в сокращенном режиме, т.е. качество будет хуже чем с 5гБ.

Опции для H64 и H128:
[i] Use lightweight autoencoder? (y/n, ?:help skip:n) : [/i] - выбрать урезанную модель. Необходимо для видеокарт с <= 4 ГБ видео памяти.

DF (5GB+) - модель от dfaker. Полнолицевая модель с разрешением 128, умная функция тренировки лиц, исключающая фон вокруг лица.

LIAEF128 (5GB+) - новая модель, как DF, только пытается морфировать исходное лицо в целевое лицо, сохраняя черты исходного лица. Морфирование не всегда хорошо, и может сделать вообще не узнаваемое лицо, в таком случае выбирайте DF.

SAE (2GB+) - новая модель для стилизованной тренировки лица. Эта модель по сути содержит все другие модели, если отключить тренировку стиля, только еще лучше. Стиль и освещение подгоняется непосредственно нейронной сетью. В конвертации вам нужно выбрать лишь режим overlay, если тренировано со стилем. При первом запуске можно настроить параметры: разрешение, количество фильтров нейронной сети и тип лица - половинное или полное. Эти параметры влияют на то, какого размера будет сеть и запустится ли на вашей видеокарте.

[b]Опции только для SAE модели:[/b]

[i]Resolution (64,128, ?:help skip:128) : [/i] - разрешение лица.
[i]AE architecture (df, liae, ?:help skip:liae) : [/i] - тип АЕ архитектуры. DF - более естественное лицо, но модель может рассыпаться если лица не похожи друг на друга. LIAE - частично исправляет непохожесть лиц подгоняя его.
[i]Use lightweight encoder? (y/n, ?:help skip:n) : [/i] - использовать ли облегченный энкодер, он быстрее на 35%, только не тестирован на различных сценах.
[i]Learn mask? (y/n, ?:help skip:y) : [/i] - учить ли маску. С изучением, маска будет более сглаженной, иначе будет использоваться грубая. Однако при стилизованной тренировки можно обойтись без изучения маски, тогда в конверторе выберите большие значения blur.
[i]Face style power ( 0.0 .. 100.0 ?:help skip:%.1f) : [/i] - скорость изучения стиля лица. Число с плавающей точкой. 0 - не учить
[i]Use pixel loss? (y/n, ?:help skip: n/default ) : [/i] - позволяет быстрее улучшать мелкие детали. Включать только после 30-40к эпох.
[i]Background style power ( 0.0 .. 100.0 ?:help skip:%.1f) : [/i] - скорость изучения стиля фона. Число с плавающей точкой. 0  - не учить
[i]AutoEncoder dims (128-1024 ?:help skip:%d) : [/i] - количество размерностей сети, больше - лучше, но может не запуститься из-за нехватки памяти. Можно уменьшать для достижения работоспособности на вашей видеокарте.
[i]Encoder/Decoder dims per channel (21-85 ?:help skip:%d) : [/i] - количество размерностей енкодера/декодера сети, больше - лучше, но может не запуститься из-за нехватки памяти. Можно уменьшать для достижения работоспособности на вашей видеокарте.
[i]Half or Full face? (h/f, ?:help skip:f) : [/i] - половинный или полный размер лица

см Советы и хитрости по моделям.

Вы можете тренировать все модели поочередно, не волнуясь о потери данных, потому что каждая модель записывается в свои файлы в папке [b]Workspace\Model\[/b]

В процессе тренировки можно выходить через [b]Enter[/b], нажав его в [b]окне Training preview[/b], и запускать в любое время, модель будет продолжать обсчитываться с той же точки.
Тренируем от 24 часов и больше. Когда результат удовлетворяет - выходим также через [b]Enter[/b], нажав его в [b]окне Training preview[/b].

Кнопка 'p'(на англ раскладке) в [b]окне Training preview[/b] обновляет предпросмотр.

В [b]окне Training preview[/b] также мы видим [b]кривую ошибки[/b]. Четкость результата может увеличиваться в процессе тренировки и без понижения кривой ошибки.

[b]7) convert ... Наложение лиц.[/b]

Выбираете ту модель, с которой тренировали.

Опция [b]debug[/b] позволяет посмотреть процесс наложения лиц и некоторую техническую информацию по каждому кадру в консоли, нажимаете пробел в окне просмотра.

Далее при запуске программа спросит об опциях:

[i]Choose mode: (1) overlay, (2) hist match, (3) hist match bw, (4) seamless (default), (5) seamless hist match, (6) raw : [/i]

Выбор режима наложения лиц.
По-умолчанию, если нажать ентер - выберет seamless.
Какую выбрать? Зависит от случая. Пробуете все и смотрите результат. Наглядное сравнение смотрите ниже в [b]Сравнительный обзор опций конвертора.[/b]
Режим 'raw' - получить сырые слои для собственной обработки в видео редакторе, например After Effects.

[i]Masked hist match? [0 or 1] (default - 1) :[/i] - Для режимов (1) hist match, (2) hist match bw, (4) seamless hist match, указывает, уравнивать ли гистограмму по маске лица.
[i]Use predicted mask? [0 or 1] (default 1) : [/i] - Использовать ли маску, которая предсказана моделью - по умолчанию да. Либо использовать маску из целевого лица.
[i]Choose erode mask modifier [-200..200] (default 0) :[/i] - Указываете насколько сжать лицевую маску. Значение < 0 - расширить маску. В отличие от FaceSwap этот параметр модифицирует адаптивное значение, а не абсолютное.
[i]Choose blur mask modifier [-200..200] (default 0) : [/i] - Указываете насколько сгладить лицевую маску. Значение < 0 - уменьшает сглаживание по-умолчанию моделями H64 и H128. В отличие от FaceSwap этот параметр модифицирует адаптивное значение, а не абсолютное.
[i]Choose seamless erode mask modifier [-100..100] (default 0) : [/i] - только для режимов seamless - модификация размеров маски, использующейся для seamless clone функции
[i]Hist match threshold. [0..255] (default - 255) :[/i] - Уменьшение значения подавляет артефакты для режимов hist-match.
[i]Choose output face scale modifier [-50..50] (default 0) : [/i] - изменить масштаб выходного лица в пределах -50+50%. Полезно когда предсказанное лицо несколько больше оригинала.
[i]Transfer color from dst face to converted final face? [0 or 1] (default 0) : [/i] - наложить цвета из оригинального лица. Иногда может быть полезно. Существенно замедляет скорость конвертации.
[i]Degrade color power of final image [0..100] (default 0) : [/i] - Степень деградации цветности конечной картинки от 0 до 100. Уменьшая общее качество картинки, можно скрыть недостатки наложения лица.
[i]Export png with alpha channel? [0..1] (default 0) : [/i] - экспортирует только лицо с альфа каналом для последующей работы в видео редакторе.

[b]Итог по наложению лиц.[/b]

В начале запускаете с отладкой, пробуя различные параметры и смотрите результат.
Запомнив подходящие значения, запускаете наложение без отладки.

Результат картинок в [b]workspace\data_dst\merged[/b] - можно использовать самому в [b]видеоредакторе[/b], либо [b]склеить[/b] в видео в п.8

[b]8) converted to avi.bat[/b]
[b]8) converted to mp4.bat[/b]
[b]8) converted to mp4(lossless+alpha).bat[/b] - mp4 без потерь с использованием alpha канала.
[b]8) converted to mov(lossless+alpha).bat[/b] - mov без потерь с использованием alpha канала. Sony Vegas с использованием QuickTime сможет использовать alpha канал из mov файла.

^ эти запускалки склеивают картинки в видео с тем же FPS и звуком, что и [b]data_dst.mp4[/b] - поэтому не удаляйте [b]data_dst.mp4[/b] из workspace папки.

[b]Всё[/b]. Результат в [b]workspace\result.avi[/b].

Если результат [b]не удовлетворил[/b], можно пробовать разные опции наложения, либо продолжать тренировать для повышения четкости, либо пробовать другую модель, либо пробовать другое исходное лицо.

[b]Дополнительная[/b] информация:

Раньше были [b]workspace backup.bat[/b], для бэкапа, но я их убрал, потому что можно и НУЖНО вручную скопировать и переименовать workspace например в workspace_собчак, тем самым сохранив резервную копию.
[/spoiler]

[spoiler="Советы и хитрости по моделям."]
Узкие лица лучше тренируются на широкие лица. Вот почему фейки с Кейджем так популярны.

[b]для модели SAE:[/b]

Эта модель по сути содержит все другие модели, если отключить тренировку стиля, только еще лучше.
SAE очень гибкая, можно подстроить либо под лучшее обобщение лиц сетью, либо под лучшую четкость изображения, либо просто чтобы заработало на вашей GPU.
Если src сборка лиц содержит количество лиц больше чем dst, модель может не сойтись. В этом случае используйте опцию Feed faces to network sorted by yaw.
Если src лицо шире чем dst, модель может не сойтись. В этом случае можете попробовать опцию 'Src face scale modifier' в -5.
Архитектура 'df' делает лицо более похожее на src, но если модель не сходится, используйте 'liae' по-умолчанию.
Если на вашей видеокарте много видеопамяти, вы можете выбрать между большим batch-size, которое улучшает обобщение лиц, и Encoder/Decoder dims размерностями, которые улучшают качество картинки.

Face стиль тренируется, чтобы перенести цвет лица, освещение, макияж. Если он уже хорошо перенесен, то продолжение тренировки с высоким значением может сделать артефакты.
Background стиль тренируется, чтобы перенести контур лица и окружение. Благодаря контуру лица, подгоняется src лицо под контур dst.

[b]Как лучше всего тренировать SAE со стилем.[/b]

Для начала запускаете тренировку с силами стилей 10.0 или выше. Если стиль лица уже хорошо натренирован, или артефакты начали проявляться, например шлем вокруг лица начнет надвигаться дальше на лицо, то сохраняете модель, запускаете снова с заменой опций, и ставите силу face стиля в 0.01, а background в 0.1-0.3
Если артефакты уже надвинулись сильно, можно на время поставить силу стилей в 0.0, а затем вернуть и продолжить тренировку до улучшения чёткости изображения.
Тренируйте с включенной опцией Write preview history, чтобы отслеживать изменения.
[/spoiler]

[spoiler="CPU версия программы"]
Соответствующая CPU версия программы содержится в отдельном торрент архиве.
На CPU работают абсолютно все стадии программы, проверено на VMWare.
DLIB убран из-за того что он работает слишком медленно, поэтому извлечение лиц только на MT.
Доступна только H64 модель. 8-е поколение Intel Core способно натренировать H64 за 2 дня.
[/spoiler]

Первый запуск программы в чистой папке из торрента будет происходить долго, т.к. компилируются GPU программы.

[spoiler="Сравнительный обзор опций конвертора."]
[url=https://github.com/iperov/DeepFaceLab/raw/master/doc/DeepFaceLab_convertor_overview.png]изображение из github[/url]
[/spoiler]

[spoiler="Нехватка памяти на Windows 10"]
Известны случаи, когда Windows 10 резервирует % видеопамяти, даже если видеокарта не используется для вывода картинки. В таком случае есть шанс, что вы не сможете использовать некоторые модели.
[/spoiler]

[spoiler="Опции командной строки (для экспериментаторов)"]
Дополнительные опции тренировки. Редактировать соответствующий .bat файл.

--force-gpu-idx N - принудительная установка номера GPU
[/spoiler]

[spoiler="Полезные ссылки"]
[url=https://www.youtube.com/channel/UCEtoVzBLuE-ni-54h7kYvsg]Мой канал фейков[/url]
[url=https://www.youtube.com/channel/UCUix6Sk2MZkVOr5PWQrtH1g/videos]Другой канал фейков[/url]
[url=https://www.reddit.com/r/GifFakes/]Фейки на реддите[/url]

[url=https://mega.nz/#F!y1ERHDaL!PPwg01PQZk0FhWLVo5_MaQ]Готовые src наборы лиц для DeepFaceLab[/url]
[url=http://www.pictriev.com/]поиск подходящей знаменитости по загруженному лицу[/url]
[url=https://findface.sex/ru/#]поиск подходящей порнозвезды по загруженному лицу[/url]
[url=https://findpornface.com]поиск подходящей порнозвезды по загруженному лицу[/url]
[url=https://pornstarbyface.com]поиск подходящей порнозвезды по загруженному лицу[/url]
[url=http://www.didshedoporn.com]поиск подходящей порнозвезды по загруженному лицу[/url]
[/spoiler]

[spoiler="Скриншоты"]
Ручное извлечение:
[img]http://i104.fastpic.ru/big/2018/0418/0f/f510f562f872a895b6119875f9d30f0f.png[/img]

Тренировка модели:
[img]http://i104.fastpic.ru/big/2018/0418/1e/bb8f3e70b350dbe73d902dd344be5e1e.png[/img]
[/spoiler]

[spoiler="Скриншот папки DeepFaceLab"]
[img]http://i105.fastpic.ru/big/2018/0507/57/d8de438a901a58493135ba1d4217fa57.jpg[/img]
[/spoiler]

[color=red]раздача обновлена[/color]

конвертор теперь работает в параллеле, что увеличило скорость конвертации в 2 раза

[color=red]раздача обновлена[/color]

пофиксил склейку в mp4 - теперь видео корректно грузится в Sony Vegas

[color=red]раздача обновлена[/color]

фикс ошибок на некоторых сэмплах

введена тестовая модель LIAEF128YAW

[color=red]раздача обновлена[/color]

фикс сортировки по хистограммам
добавлены сортировка по яркости, цвету, хистограммо-размытости

[color=red]раздача обновлена[/color]

Нужно перезапустить тренировку всех моделей (удалить папку model из workspace)
Апгрейд движка на TensorFlow 1.8.0, CUDA 9.0, CuDNN 7.0
Улучшено качество всех моделей.
До/после LIAEF128 https://www.youtube.com/watch?v=_52EaJi1USI
H128 Кейдж https://github.com/iperov/DeepFaceLab/raw/master/doc/H128_Cage_0.jpg

[color=red]раздача обновлена[/color]

проект переименован в DeepFaceLab
апгрейд движка на Python 3.6.5.
улучшено качество тренировки моделей
улучшено качество конвертора
рекомендуется (но не обязательно) перезапустить тренировки

[color=red]раздача обновлена[/color]

фикс зависающей выборки лиц

[color=red]раздача обновлена[/color]

фиксы
улучшено качество извлечения лиц
изменены минимальные требования видеопамяти для моделей
H128 для 4Гб запускается урезанной версией как и для 3Гб.

[color=red]раздача обновлена[/color]

фикс серьезного бага с которым модель не учила половину лиц

[color=red]раздача обновлена[/color]

фиксы
Ускорена тренировка моделей H64 и H128 от 7 до 15%.
Добавлена AVATAR модель. Пример https://coub.com/view/1954x3
фикс бага финальной сборки mp4, когда изначальное видео имело нестандартный кодек, например снятое из смартфона

[color=red]раздача обновлена[/color]

Обновление версий внутренних модулей.

Улучшение работы masked hist match - меньше ярких пересветов.

Новые опции в конверторе:

Choose output face scale modifier [-50..50] (default 0) : - изменить масштаб выходного лица в пределах -50+50%. Полезно когда предсказанное лицо несколько больше оригинала.
Transfer color from original DST image? [0..1] (default 0) : - наложить цвета из оригинального лица. Иногда может быть полезно. Существенно замедляет скорость конвертации.
Degrade color power of final image [0..100] (default 0) :  - Степень деградации цветности конечной картинки от 0 до 100. Уменьшая общее качество картинки, можно скрыть недостатки наложения лица.
Export png with alpha channel? [0..1] (default 0) : - экспортирует только лицо с альфа каналом для последующей работы в видео редакторе.

это обновление может выдавать ошибку в конце работы какого-либо этапа

[spoiler]
Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x00000000365A7898>>
Traceback (most recent call last):
  File "F:\DeepFaceLabTorrent\_internal\bin\lib\site-packages\tensorflow\python\client\session.py", line 1413, in __del__
AttributeError: 'NoneType' object has no attribute 'raise_exception_on_not_ok_status'
[/spoiler]
это не влияет на работу программы и результат. Ждем фикс от keras.

Для владельцев 2080 ждём выхода tensorflow 1.13.0 ближе к концу января.

[color=red]раздача обновлена[/color]

добавлены способы конвертации в видео при использовании "Export png with alpha channel".
8) converted to mp4(lossless+alpha).bat - конвертирует в видео mp4 без потерь с использованием alpha канала.
8) converted to mov(lossless+alpha).bat - конвертирует в видео mov без потерь с использованием alpha канала. Sony Vegas с использованием QuickTime сможет использовать alpha канал из mov файла.

[color=red]раздача обновлена[/color]

исправлено зависание в режиме debug конвертора, если 60 секунд ничего не делалось
добавлена опция hist-match threshold в конвертор для режимов hist-match. Уменьшение значения позволяет подавить артефакты hist-match.
Добавлена сравнительная инфографика по конвертору.

[color=red]раздача обновлена[/color]

улучшена и ускорена сортировка [b]by blur[/b]

ускорена сортировка [b]by hist[/b]

улучшена и ускорена сортировка [b]by hist-dissim[/b]

добавлены опции в конвертор:

[i]Use predicted mask? [0 or 1] (default 1) : [/i]
Использовать ли маску, которая предсказана моделью - по умолчанию да. Либо использовать маску из целевого лица.

[i]Choose seamless erode mask modifier [-100..100] (default 0) : [/i]
только для режимов seamless - модификация размеров маски, использующейся для seamless clone функции

добавлена опция в src сортировщик:

[b]4.2.other) data_src sort by black.bat[/b]

Сортирует по количеству черных пикселей в конец списка. Позволяет отсеить лица вырезанные экраном.

[color=red]раздача обновлена[/color]

добавлена CPU версия с одной H64 моделью. 8-е поколение Intel Core способно натренировать H64 за 2 дня.
Соответствующая CPU версия программы содержится в отдельной папке.
На CPU работают абсолютно все стадии программы, проверено на VMWare.

[color=red]раздача обновлена[/color]

добавлена новая модель U-net Face Morpher. Новая модель для морфирования лица.
При первом запуске можно настроить параметры: разрешение, количество фильтров нейронной сети, подгонять ли стиль, и тип лица - половинное или полное.
Эти параметры влияют на то, какого размера будет сеть и запустится ли на вашей видеокарте.
Пример фейка с использованием UFM - https://www.youtube.com/watch?v=ZU8rtypuEjc

удалена модель AVATAR - бесполезная, была только для демо.
удалена MIAEF128 - используйте теперь UFM.
удалена LIAEF128YAW - опция сортировки доступна теперь для всех моделей
Все модели теперь спрашивают различные опции при первом запуске.
Выбирая ... sess opts.bat можно изменить некоторые опции для текущей сессии.
Исправлен баг когда конвертор всегда использовал НЕ предсказанную маску.
сортировка [b]by hist[/b] вернута в положение до ускорения, т.к. при сортировке тысяч лиц возникает нехватка памяти
повышен битрейт конвертации в avi/mp4 до 16Mbit

[color=red]раздача обновлена[/color]

убрана UFM модель
добавлена новая модель SAE
сравнение SAE против UFM https://www.youtube.com/watch?v=ywiv0_PTp1w

сортировка [b]by hist[/b] снова очень быстрая, но только для сотен тысяч изображений. 500к изображений отсортировалось за 2.5часа.

Встроенный просмотрщик изображений заменён на XnViewMP - работает в несколько раз быстрее старого FastStone и не виснет при сотнях тысячах изображений.

[color=red]раздача обновлена[/color]

исправления.

добавлена final сортировка для сборки src набора лиц. Идеален для выборки лучших из десятков тысяч предварительно очищенных лиц.

по ссылке "Готовые src наборы лиц для DeepFaceLab" добавлен набор лиц Путина собранный методом final сортировки

[color=red]раздача обновлена[/color]

"extract PNG from" теперь более не удаляет всю папку data, а только png файлы в корне

исправлен баг при конвертации

в SAE модель добавлены различные опции - инструкция обновлена

добавлен режим 'raw' в конвертер - позволяет получить сырые слои для собственной обработки в AfterEffects

[color=red]раздача обновлена[/color]

фикс бага при ручном извлечении

извлечение dst лиц теперь всегда создаёт aligned_debug папку с отладочными кадрами

[color=red]раздача обновлена[/color]
теперь
При НЕ первом запуске модели, спросит:
[i]Press enter in 2 seconds to override some model settings.[/i]
если вы нажмете ентер втечение 2х секунд, то появится возможность заменить некоторые опции модели. + они сохранятся и на следующие запуски
поэтому отпала необходимость в отдельном sess opts.bat

убрана возможность тренировки в Multi GPU - потому что по факту это никогда не работало.
Тренировка происходила только на одном GPU, а другие просто в холостую крутили предсказания.

Вместо этого пользователям с мульти GPU теперь могут тренировать одновременно отдельные фейки более удобно.
Для этого вы должны скопировать полностью папку DeepFaceLabTorrent например в DeepFaceLabTorrent2
И при первом запуске , а также последующих запусках делать "override" настроек, где вам предложено будет выбрать какой GPU использовать.

добавлены новые опции в SAE
[i]Use lightweight encoder? (y/n, ?:help skip:n) : [/i] - использовать ли облегченный энкодер, он быстрее на 35%, только не тестирован на различных сценах.
[i]Face style power (0..100 ?:help skip:100) : [/i] - скорость изучения стиля лица. 0 - не учить
[i]Background style power (0..100 ?:help skip:100) : [/i] - скорость изучения стиля фона. 0  - не учить

фиксы

[color=red]раздача обновлена[/color]

исправлена некорректная работа, когда путь к папке содержал пробелы

[color=red]раздача обновлена[/color]

исправления

исправлена работа на некоторых видео картах ноутбуков с 2GB памятью

SAE модели нужно тренировать заново.
в SAE добавлены опции

[i]Encoder/Decoder dims per channel (21-85 ?:help skip:%d) : [/i] - количество размерностей енкодера/декодера сети, больше - лучше, но может не запуститься из-за нехватки памяти. Можно уменьшать для достижения работоспособности на вашей видеокарте.
[i]Use adaptive kernel size? (y/n, ?:help skip:n) : [/i] - использовать ли адаптивный размер ядра, позволяет в некоторых случаях избавиться от "прыгающих" частей лица

[color=red]раздача обновлена[/color]

теперь имея мульти-GPU можно тренировать одну сцену на разных моделях или опциях одной модели без клонирования папок. Просто выбираете индекс GPU на старте тренировки/конвертации и файлы модели будут содержать префикс этой GPU в имени.
Если оставить выбор GPU по-умолчанию, то выберется лучшая GPU и файлы модели НЕ будут содержать префикс.

H64 и H128: добавлена опция Lighter autoencoder , это тоже самое как было до обновления, когда ваша GPU имела <= 4 ГБ видеопамяти. Т.е. теперь имея 5 ГБ и больше вы можете выбрать урезанную модель.

RecycleGAN: ушёл в архив.

SAE: по-умолчанию сила стиля теперь 10.0 (вместо 100). Также значение стиля теперь плавающее число в районе 0.0 до 100.0

добавлен скрипт [b]3.other) denoise extracted data_dst.bat[/b]
делается перед извлечением dst лиц! делает проход по извлеченным видео кадрам убирая шум, сохраняя четкими грани.
Позволяет тем самым сделать финальный фейк более правдоподобным, т.к. нейронная сеть не способна сделать детальную текстуру кожи, но грани делает вполне четкими.
Поэтому, если весь кадр будет более "замылен", то и фейк будет казаться более правдоподобным. Особенно актуально для фильмовых сцен, которые обычно очень четкие.

[color=red]раздача обновлена[/color]

улучшена SAE модель, нужно перезапустить тренировку. Теперь SAE лучше чем все другие модели даже если тренировать БЕЗ стиля.
SAE : добавлена опция 'learn mask' - учить ли маску, см обновленную инструкцию
SAE : в конверторе добавлено обрезание маски по краям, чтобы исключить пересветленные линии у границ

инструкция обновлена, добавлен раздел "Советы и хитрости по моделям." в котором написано как тренировать SAE со стилем.

теперь вся отладочная информация по работе движка с GPU будет отображаться всегда, она добавит немного дополнительного текста, зато те у кого могут быть проблемы с железом смогут более детально сообщать о них

[color=red]раздача обновлена[/color]

фиксы / оптимизации

SAE: убрана опция adaptive kernel size. Обратной совместимости нет. если она у вас была включена, нужно стартануть тренировку заново

aligned_debug для dst теперь сохраняются в jpeg с низким качеством

добавлен просмотр aligned_debug через запуск
5.1) data_dst check results debug.bat

добавлена новая возможность
5) data_dst extract faces MANUAL FIX DELETED ALIGNED DEBUG
позволяет переизвлечь те кадры из DST, чьи algned_debug были удалены.
Для чего это нужно? Чтобы сделать фейк качественнее, нужно проверять DST кадры в папке aligned_debug, просмотреть их можно через 5.1) data_dst check results debug.bat
Если где-то увидите, что контур лица сильно отличается от реального, то удаляете этот кадр в aligned_debug, и запускаете 5) data_dst extract faces MANUAL FIX DELETED ALIGNED DEBUG
Произойдет ручное переизвлечение удалённых кадров.
Видео с которым станет всё понятно https://www.youtube.com/watch?v=7z1ykVVCHhM

[color=red]раздача обновлена[/color]

ускорена работа [i]5) data_dst extract faces MANUAL FIX DELETED ALIGNED DEBUG[/i] с большим количеством файлов

все прогресс-бары переведены в режим ascii для корректной работы на китайских windows

SAE: добавлена опция [i]Use pixel loss? (y/n, ?:help skip: n/default ) : [/i] - позволяет быстрее улучшать мелкие детали. Включать только после 30-40к эпох.

[color=red]раздача обновлена[/color]

исправлен баг с курсором при извлечении лиц на Windows 10

встроенный просмотрщик: убраны некоторые ненужные всплывающие окна, отключено сохранение каталога эскизов, который возростал до нескольких гигабайт